<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xi="http://www.w3.org/2001/XInclude" version="5.0" xml:lang="hu">
    <info>
        <title>Helló, Valaki!</title>
        <keywordset>
            <keyword/>
        </keywordset>
    </info>
    
    <section>
        <title>FUTURE tevékenység editor</title>
        <para>
            A feladatban egy hibát kellett kijavítani a programban. Ha egy ideig tesztelgetjük
            a programot rögtön észre lehet venni, hogy csak egy Új altevékenységet lehet létrehozni.
        </para>
        <mediaobject>
            <imageobject>
                <imagedata fileref="future1.jpg"></imagedata>
            </imageobject>
        </mediaobject>
        <mediaobject>
            <imageobject>
                <imagedata fileref="future1cmd.jpg"></imagedata>
            </imageobject>
        </mediaobject>
        <para>
            Tehát hiába próbálunk 2 vagy több altevékenységet létrehozni mindig ezt a hibát
            kapjuk ami fent a konzolon látszik. Ezt a bugot viszonylag egyszerűen lehetett orvosolni.
        </para>
        <programlisting language="java">
<![CDATA[public TextFieldTreeCell(javafx.scene.control.TextArea propsEdit) {
    this.propsEdit = propsEdit;
    javafx.scene.control.MenuItem subaMenuItem = new javafx.scene.control.MenuItem("Új altevékenység");//"New subactivity");
    addMenu.getItems().add(subaMenuItem);
    subaMenuItem.setOnAction((javafx.event.ActionEvent evt) -> {
        int i = 1;
        while(true) {
        java.io.File file = getTreeItem().getValue();

             java.io.File f = new java.io.File(file.getPath() + System.getProperty("file.separator") + "Új altevékenység" + i);

            if (f.mkdir()) {
                javafx.scene.control.TreeItem<java.io.File> newAct
//                           = new javafx.scene.control.TreeItem<java.io.File>(f, new javafx.scene.image.ImageView(actIcon));
                       = new FileTreeItem(f, new javafx.scene.image.ImageView(actIcon));                            
                getTreeItem().getChildren().add(newAct);
                break;
            } else {
                ++i;
                //System.err.println("Cannot create " + f.getPath());

            }
        }

    });]]>
        </programlisting>
        <para>
            Egy végtelen ciklust kellett létrehozni a mappák létrehozásához egy számlálóval,
            így nem jöhet létre ugyanaz a mappa kétszer.
        </para>
        <mediaobject>
            <imageobject>
                <imagedata fileref="future2.jpg"></imagedata>
            </imageobject>
        </mediaobject>
        <para>
            Így mostmár tetszőleges számú altevékenységet lehet létrehozni.
        </para>
    </section>
    
    <section>
        <title>SamuCam</title>
        <para>
            Azt a feladatot kaptuk, hogy a SamuCam projektben mutassunk rá a webkamera
            kezelésére. A program fordításához és futtatásához szükség van az opencv 2.4.9-es
            verziójára és a Qt valamilyen verziójára is. Valamint a program könyvtárába kell
            helyezni a lbpcascade_frontalface.xml-t.
        </para>
        <programlisting language="c++">
<![CDATA[SamuCam::SamuCam ( std::string videoStream, int width = 176, int height = 144 )
  : videoStream ( videoStream ), width ( width ), height ( height )
{
  openVideoStream();
}

SamuCam::~SamuCam ()
{
}]]>
        </programlisting>
        <para>
            A program a parancssori futtatáskor megadott argumentumként kapja meg az IP címet
            ahonnan meg kell nyitnia a kamerát. Ha az eszközünkön lévő kamerát szeretnénk
            megnyitni akkor meg kell adni egy device ID-t, ez alapesetben 0 jelent.
        </para>
        <programlisting language="c++">
<![CDATA[void SamuCam::openVideoStream()
{
  videoCapture.open ( videostream );

  videoCapture.set ( CV_CAP_PROP_FRAME_WIDTH, width );
  videoCapture.set ( CV_CAP_PROP_FRAME_HEIGHT, height );
  videoCapture.set ( CV_CAP_PROP_FPS, 10 );
}]]>
        </programlisting>
        <para>
            Az openVideoStream()-ben a videoCapture.open() függvénnyel megnyitjuk a kamerát.
            A videoCapture.set()-tel pedig beállítjuk a szélességét, magasságát és az fps
            számot.
        </para>
        <programlisting language="c++">
<![CDATA[void SamuCam::run()
{

  cv::CascadeClassifier faceClassifier;

  std::string faceXML = "lbpcascade_frontalface.xml"; // https://github.com/Itseez/opencv/tree/master/data/lbpcascades

  if ( !faceClassifier.load ( faceXML ) )
    {
      qDebug() << "error: cannot found" << faceXML.c_str();
      return;
    }]]>
        </programlisting>
        <para>
            A run() metóduson belül először példányosítunk egy CascadeClassifier-t ez
            alkalmas az Opencv-ben az objektumok felismerésére. Ezután megnyitjuk a már
            említett xml fájlt és ezt átadjuk a CascadeClassifier-nek, így válik lehetővé
            az arc felismerés. Majd lekezeljük a hibát ha nem sikerül betölteni az xmlt.
        </para>
        <programlisting language="c++">
<![CDATA[cv::Mat frame;
while ( videoCapture.isOpened() )
    {

      QThread::msleep ( 50 );
      while ( videoCapture.read ( frame ) )
        {

          if ( !frame.empty() )
            {

              cv::resize ( frame, frame, cv::Size ( 176, 144 ), 0, 0, cv::INTER_CUBIC );

              std::vector<cv::Rect> faces;
              cv::Mat grayFrame;

              cv::cvtColor ( frame, grayFrame, cv::COLOR_BGR2GRAY );
              cv::equalizeHist ( grayFrame, grayFrame );

              faceClassifier.detectMultiScale ( grayFrame, faces, 1.1, 4, 0, cv::Size ( 60, 60 ) );

              if ( faces.size() > 0 )
                {

                  cv::Mat onlyFace = frame ( faces[0] ).clone();

                  QImage* face = new QImage ( onlyFace.data,
                                              onlyFace.cols,
                                              onlyFace.rows,
                                              onlyFace.step,
                                              QImage::Format_RGB888 );

                  cv::Point x ( faces[0].x-1, faces[0].y-1 );
                  cv::Point y ( faces[0].x + faces[0].width+2, faces[0].y + faces[0].height+2 );
                  cv::rectangle ( frame, x, y, cv::Scalar ( 240, 230, 200 ) );


                  emit  faceChanged ( face );
                }

              QImage*  webcam = new QImage ( frame.data,
                                             frame.cols,
                                             frame.rows,
                                             frame.step,
                                             QImage::Format_RGB888 );

              emit  webcamChanged ( webcam );

            }

          QThread::msleep ( 80 );

        }

      if ( ! videoCapture.isOpened() )
        {
          openVideoStream();
        }

    }

}
]]>
        </programlisting>
        <para>
            Létrehozunk egy Mat típusú  frame-et ebben tároljuk a kép adatokat. A run végén
            következik ez a két szép egymásba ágyazott while ciklus. Ez addig fog futni amíg
            a webkamera megvan nyitva ezt a videoCapture.isOpened()-el ellenőrizzük, ami
            true-val tér vissza, ha megvan nyitva és false-al ha nincs. Ellenőrizzük, hogy a
            kép nem üres. A resize-al újra méretezzük a képet. A cvtColor-al pedig átalakítjuk
            szürkeskálásba a színes képet és az equalizeHist-el kiegyenlítjük a hisztogramot.
            A detectMultiScale-el keressük meg a fejet a képen ezt kimentjük a faces-be.
            Ezt adjuk át a SamuBrain-nek ami feldolgozza és frissíti a webcam képét és
            az ismétlődik addig,amíg be nem zárjuk a programot.
        </para>
        <para>
            A program futás közben:
        </para>
        <mediaobject>
            <imageobject>
                <imagedata fileref="samucam.png"></imagedata>
            </imageobject>
        </mediaobject>
    </section>
    
    <section>
        <title>BrainB</title>
        <para>
            Azt a feladatot kaptuk, hogy a BrainB-ben mutassuk be a Qt slot-signal
            mechanizmusát. 
        </para>
        <para>
            Ezt a mechanizmust objektumok közötti kommunikálásra lehet használni.
            Egy signalt, vagyis egy jelet ad ki a program, ha egy bizonyos esemény bekövetkezik.
            A slot pefig egy olyan függvény amelyet a signal bekövetkezése esetén meg
            kell hívni. A connect függvénnyel lehet összekapcsolni egy signal és egy slotot.
            A két mechanizmus típus biztos ami annyit tesz, hogy a szignatúrájuknak egyezzniük
            kell. Valamint tetszőleges számú argumentumot felhevetnek bármilyen típúsból.
        </para>
        <para>
            Így néz ki ez a BrainB-ben:
        </para>
        <programlisting language="c++">
<![CDATA[connect ( brainBThread, SIGNAL ( heroesChanged ( QImage, int, int ) ),
          this, SLOT ( updateHeroes ( QImage, int, int ) ) );

connect ( brainBThread, SIGNAL ( endAndStats ( int ) ),
          this, SLOT ( endAndStats ( int ) ) );]]>
        </programlisting>
        <para>
            Itt az történik, hogy ha a herosChanged signal befut akkor az az updateHeros
            függvényt elindítja, ugyanez az endAndStat-nál.
        </para>
        <programlisting language="c++">
<![CDATA[void draw () {

    cv::Mat src ( h+3*heroRectSize, w+3*heroRectSize, CV_8UC3, cBg );

    for ( Hero & hero : heroes ) {

        cv::Point x ( hero.x-heroRectSize+dispShift, hero.y-heroRectSize+dispShift );
        cv::Point y ( hero.x+heroRectSize+dispShift, hero.y+heroRectSize+dispShift );

        cv::rectangle ( src, x, y, cBorderAndText );

        cv::putText ( src, hero.name, x, cv::FONT_HERSHEY_SIMPLEX, .35, cBorderAndText, 1 );

        cv::Point xc ( hero.x+dispShift , hero.y+dispShift );

        cv::circle ( src, xc, 11, cCenter, CV_FILLED, 8, 0 );

        cv::Mat box = src ( cv::Rect ( x, y ) );

        cv::Mat cbox ( 2*heroRectSize, 2*heroRectSize, CV_8UC3, cBoxes );
        box = cbox*.3 + box*.7;

    }

    cv::Mat comp;

    cv::Point focusx ( heroes[0].x- ( 3*heroRectSize ) /2+dispShift, heroes[0].y- ( 3*heroRectSize ) /2+dispShift );
    cv::Point focusy ( heroes[0].x+ ( 3*heroRectSize ) /2+dispShift, heroes[0].y+ ( 3*heroRectSize ) /2+dispShift );
    cv::Mat focus = src ( cv::Rect ( focusx, focusy ) );

    cv::compare ( prev, focus, comp, cv::CMP_NE );

    cv::Mat aRgb;
    cv::extractChannel ( comp, aRgb, 0 );

    bps = cv::countNonZero ( aRgb ) * 10;

    //qDebug()  << bps << " bits/sec";

    prev = focus;

    QImage dest ( src.data, src.cols, src.rows, src.step, QImage::Format_RGB888 );
    dest=dest.rgbSwapped();
    dest.bits();

    emit heroesChanged ( dest, heroes[0].x, heroes[0].y );

}]]>
        </programlisting>
        <para>
            Ebben a függvényben adja ki a signalt. Ezzel:
            <function> emit heroesChanged ( dest, heroes[0].x, heroes[0].y );</function>
        </para>
        <programlisting language="c++">
<![CDATA[void BrainBWin::updateHeroes ( const QImage &image, const int &x, const int &y )
{

        if ( start && !brainBThread->get_paused() ) {

                int dist = ( this->mouse_x - x ) * ( this->mouse_x - x ) + ( this->mouse_y - y ) * ( this->mouse_y - y );

                if ( dist > 121 ) {
                        ++nofLost;
                        nofFound = 0;
                        if ( nofLost > 12 ) {

                                if ( state == found && firstLost ) {
                                        found2lost.push_back ( brainBThread->get_bps() );
                                }

                                firstLost = true;

                                state = lost;
                                nofLost = 0;
                                //qDebug() << "LOST";
                                //double mean = brainBThread->meanLost();
                                //qDebug() << mean;

                                brainBThread->decComp();
                        }
                } else {
                        ++nofFound;
                        nofLost = 0;
                        if ( nofFound > 12 ) {

                                if ( state == lost && firstLost ) {
                                        lost2found.push_back ( brainBThread->get_bps() );
                                }

                                state = found;
                                nofFound = 0;
                                //qDebug() << "FOUND";
                                //double mean = brainBThread->meanFound();
                                //qDebug() << mean;

                                brainBThread->incComp();
                        }

                }

        }
        pixmap = QPixmap::fromImage ( image );
        update();
}]]>
        </programlisting>
        <para>
            És ez a függvény fog lefutni mitán megkpata a signalt.
        </para>
        <programlisting language="c++">
<![CDATA[void BrainBThread::run()
{
        while ( time < endTime ) {

                QThread::msleep ( delay );

                if ( !paused ) {

                        ++time;

                        devel();

                }

                draw();

        }

        emit endAndStats ( endTime );

}]]>
        </programlisting>
        <para>
            Az endAndStats-nál ez a függvény fog signalozni. Ezzel:
            <function>emit endAndStats ( endTime );</function>
        </para>
        <programlisting language="c++">
<![CDATA[void BrainBWin::endAndStats ( const int &t )
{

        qDebug()  << "\n\n\n";
        qDebug()  << "Thank you for using " + appName;
        qDebug()  << "The result can be found in the directory " + statDir;
        qDebug()  << "\n\n\n";

        save ( t );
        close();
}]]>
        </programlisting>
        <para>
            És ezt a függvényt fogja elindítani.
        </para>
        <para>
            Csak, hogy lássuk a programot futás közben:
        </para>
        <mediaobject>
            <imageobject>
                <imagedata fileref="BrainB.jpg"></imagedata>
            </imageobject>
        </mediaobject>
    </section>
</chapter>

